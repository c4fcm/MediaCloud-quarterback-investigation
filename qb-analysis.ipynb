{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodecsv as csv\n",
    "from PyDictionary import PyDictionary\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open manually coded words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manual-word-tags.csv contains 249 most common words in corpus,\n",
    "# manually sorted into \"name\", \"personal\", \"stopword\", \"descriptor\", \"health\", and \"action\"\n",
    "# here we import them into a dictionary, \"codings\"\n",
    "\n",
    "codings = {}\n",
    "reader = csv.reader( open('manual-word-tags.csv','rU'))\n",
    "reader.next()\n",
    "for row in reader:\n",
    "    word = row[0]\n",
    "    tag = row[1]\n",
    "    if tag not in codings:\n",
    "        codings[tag] = []\n",
    "    codings[tag].append(word)\n",
    "for category,terms in codings.iteritems():\n",
    "    print \"%s - %d terms\" % (category, len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use PyDictionary to broaden word categories by getting synonyms of all words in each category\n",
    "\n",
    "to_expand = ['personal','descriptor','health','action']\n",
    "expanded_codings = {}\n",
    "for category in to_expand:\n",
    "    \n",
    "    terms = codings[category][:] \n",
    "    expanded_codings[category] = terms #add terms we already have\n",
    "    \n",
    "    dictionary = PyDictionary(terms)\n",
    "    synonymlists = dictionary.getSynonyms(formatted=False)\n",
    "    \n",
    "    #\"synonymlists\" is a list of lists. each list is synonyms of a word in \"terms\"\n",
    "    #dictionary.getSynonyms(formatted = True) would return a list of dicts\n",
    "    \n",
    "    synonyms = [word for sublist in synonymlists for word in sublist ] #flatten list of lists into a list\n",
    "    synonyms = list(set(synonyms)) #remove duplicates\n",
    "    \n",
    "    expanded_codings[category] += synonyms\n",
    "    \n",
    "for category,terms in expanded_codings.iteritems():\n",
    "    print \"%s - %d terms\" % (category, len(terms))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do we like our new categories of words? e.g. \"flower\" and \"paraphernalia\" are both in \"action\"\n",
    "# and \"damaged\" and \"wounded\" are in \"descriptor\"\n",
    "# and \"bankrupt\" is in \"health\"\n",
    "\n",
    "# also, should check if any word appears in multiple categories - how choose which one?\n",
    "expanded_codings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/word_freq_by_race.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top200white = df.sort_values('white',ascending=False).head(200)['word']\n",
    "#for some reason, #24048 gets put at the top?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top200other = df.sort_values('other',ascending=False).head(200)['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top200other[~top200other.isin(top200white)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = PyDictionary(\"threw\")\n",
    "dictionary.getSynonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Category Use by Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uses = {}\n",
    "for category,terms in codings.iteritems():\n",
    "    white_uses = 0\n",
    "    other_uses = 0\n",
    "    uses[category] = {'white':df[df['word'].isin(terms)].sum(axis=0)['white pct'],\n",
    "                      'other':df[df['word'].isin(terms)].sum(axis=0)['other pct']}\n",
    "uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Count number of times each qb is mentioned in their corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count number of times each qb is mentioned (full name) in their own .txt file of sentences\n",
    "\n",
    "qbfiles = listdir(r'data\\corpora')\n",
    "names = [name[:-4] for name in qbfiles]\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for n in names:\n",
    "    filename = 'data\\\\corpora\\\\'+n+'.txt'\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        alltext = f.read()\n",
    "    \n",
    "    counts[n] = alltext.count(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[race\n",
       " hispanic       Tony Romo\n",
       " hispanic    Mark Sanchez\n",
       " Name: qb_name, dtype: object, 'Marcus Mariota', race\n",
       " black         Tyrod Taylor\n",
       " black            EJ Manuel\n",
       " black           Cam Newton\n",
       " black          Matt Cassel\n",
       " black         Josh Freeman\n",
       " black    Teddy Bridgewater\n",
       " black         Michael Vick\n",
       " black     Colin Kaepernick\n",
       " black       Russell Wilson\n",
       " black       Jameis Winston\n",
       " Name: qb_name, dtype: object]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get races of each quarterback according to qb_table\n",
    "races = pd.read_csv('qb-table.csv', index_col=2)\n",
    "allraces = list(set(races.index))\n",
    "\n",
    "whiteqbs = list(races.loc['white']['qb_name'])\n",
    "\n",
    "nonwhiteqbs = []\n",
    "for race in allraces:\n",
    "    if race != 'white':\n",
    "        addnames = races.loc[race]['qb_name']\n",
    "        nonwhiteqbs += [addnames]\n",
    "\n",
    "#nonwhiteqbs = [list(races.loc[race]['qb_name']) for race in allraces if race != 'white']\n",
    "nonwhiteqbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
